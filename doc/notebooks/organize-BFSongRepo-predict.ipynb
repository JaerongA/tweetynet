{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from configparser import ConfigParser\n",
    "import os\n",
    "from pathlib import Path\n",
    "import json\n",
    "import shutil\n",
    "\n",
    "import numpy as np\n",
    "import tqdm\n",
    "\n",
    "import vak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BIRDS = ['bl26lb16', 'gy6or6', 'or60yw70', 'gr41rd51']\n",
    "\n",
    "CONFIGS_DIR = Path('../../src/configs/')\n",
    "BF_CONFIGS = sorted(list(CONFIGS_DIR.glob('*BFSongRepository*ini')))\n",
    "\n",
    "\n",
    "configs_by_bird = {\n",
    "    bird: [bf_config for bf_config in BF_CONFIGS if bird in str(bf_config)][0]\n",
    "    for bird in BIRDS\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BFSongRepo = Path('~/Documents/data/BFSongRepository/').expanduser()\n",
    "\n",
    "all_notmats = list(BFSongRepo.glob('*/*/*.not.mat'))\n",
    "bird_date_dirs = set([notmat.parents[0] for notmat in all_notmats])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "copy all .cbins with .not.mats into a sub-directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 17/87 [00:00<00:00, 169.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "copying annotated songs in {bird_date_dir} into sub-directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 87/87 [00:00<00:00, 190.17it/s]\n",
      " 16%|█▋        | 33/202 [00:00<00:00, 322.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "copying annotated songs in {bird_date_dir} into sub-directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 202/202 [00:00<00:00, 301.39it/s]\n",
      " 18%|█▊        | 21/117 [00:00<00:00, 208.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "copying annotated songs in {bird_date_dir} into sub-directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 117/117 [00:00<00:00, 200.95it/s]\n",
      " 29%|██▉       | 21/73 [00:00<00:00, 204.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "copying annotated songs in {bird_date_dir} into sub-directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 73/73 [00:00<00:00, 209.46it/s]\n",
      " 17%|█▋        | 27/162 [00:00<00:00, 266.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "copying annotated songs in {bird_date_dir} into sub-directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 162/162 [00:00<00:00, 317.07it/s]\n",
      " 33%|███▎      | 71/215 [00:00<00:00, 702.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "copying annotated songs in {bird_date_dir} into sub-directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 215/215 [00:00<00:00, 686.06it/s]\n",
      " 10%|█         | 21/203 [00:00<00:00, 204.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "copying annotated songs in {bird_date_dir} into sub-directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 203/203 [00:00<00:00, 216.44it/s]\n",
      " 43%|████▎     | 22/51 [00:00<00:00, 216.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "copying annotated songs in {bird_date_dir} into sub-directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51/51 [00:00<00:00, 217.09it/s]\n",
      " 28%|██▊       | 26/92 [00:00<00:00, 257.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "copying annotated songs in {bird_date_dir} into sub-directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 92/92 [00:00<00:00, 119.27it/s]\n",
      " 44%|████▍     | 33/75 [00:00<00:00, 325.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "copying annotated songs in {bird_date_dir} into sub-directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 75/75 [00:00<00:00, 327.56it/s]\n",
      " 17%|█▋        | 30/172 [00:00<00:00, 274.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "copying annotated songs in {bird_date_dir} into sub-directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 172/172 [00:00<00:00, 519.54it/s]\n",
      "  0%|          | 0/378 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "copying annotated songs in {bird_date_dir} into sub-directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 378/378 [00:03<00:00, 106.43it/s]\n",
      " 33%|███▎      | 70/212 [00:00<00:00, 689.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "copying annotated songs in {bird_date_dir} into sub-directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 212/212 [00:00<00:00, 652.16it/s]\n",
      "100%|██████████| 39/39 [00:00<00:00, 694.33it/s]\n",
      "  0%|          | 0/111 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "copying annotated songs in {bird_date_dir} into sub-directory\n",
      "\n",
      "copying annotated songs in {bird_date_dir} into sub-directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 111/111 [00:02<00:00, 41.22it/s]\n",
      " 30%|███       | 21/70 [00:00<00:00, 208.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "copying annotated songs in {bird_date_dir} into sub-directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 70/70 [00:00<00:00, 219.51it/s]\n",
      " 11%|█         | 22/196 [00:00<00:00, 214.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "copying annotated songs in {bird_date_dir} into sub-directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 196/196 [00:00<00:00, 208.80it/s]\n",
      " 36%|███▋      | 59/162 [00:00<00:00, 589.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "copying annotated songs in {bird_date_dir} into sub-directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 162/162 [00:00<00:00, 580.73it/s]\n"
     ]
    }
   ],
   "source": [
    "# for bird_date_dir in bird_date_dirs:\n",
    "#     has_notmat = bird_date_dir.joinpath('has_notmat')\n",
    "#     has_notmat.mkdir(exist_ok=True)\n",
    "#     notmats_this_date_dir = sorted(list(bird_date_dir.glob('*.not.mat')))\n",
    "#     print(f'\\ncopying annotated songs in {bird_date_dir} into sub-directory')\n",
    "#     for notmat in tqdm.tqdm(notmats_this_date_dir):\n",
    "#         shutil.copy(notmat, dst=has_notmat)\n",
    "#         cbin = notmat.parent.joinpath(\n",
    "#             Path(notmat.stem).stem\n",
    "#         )\n",
    "#         shutil.copy(cbin, dst=has_notmat)  # cbin_file, stem.stem removes .not.mat\n",
    "#         rec = notmat.parent.joinpath(\n",
    "#             Path(Path(notmat.stem).stem).stem + '.rec'\n",
    "#         )\n",
    "#         shutil.copy(rec, dst=has_notmat)\n",
    "#         tmp = notmat.parent.joinpath(\n",
    "#             Path(Path(notmat.stem).stem).stem + '.tmp'\n",
    "#         )\n",
    "#         shutil.copy(tmp, dst=has_notmat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get dirs to predict for each bird"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs_to_predict = {}\n",
    "for bird in BIRDS:\n",
    "    these = [\n",
    "        bird_date_dir for bird_date_dir in bird_date_dirs\n",
    "        if bird in str(bird_date_dir)\n",
    "    ]\n",
    "    these = [path.joinpath('has_notmat')\n",
    "             for path in these]\n",
    "    dirs_to_predict[bird] = these"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "spect_params = {'fft_size': 512,\n",
    "                'step_size': 62,\n",
    "                'freq_cutoffs': [500, 10000],\n",
    "                'thresh': 6.25,\n",
    "                'transform_type': 'log_spect'}\n",
    "sp_nt = vak.config.spectrogram.SpectConfig(**spect_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "NETWORKS = vak.network._load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-7-e37b62efa538>, line 116)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-7-e37b62efa538>\"\u001b[0;36m, line \u001b[0;32m116\u001b[0m\n\u001b[0;31m    with open(os.path.joinpath(dir_to_predict,'test.json') as fp:\u001b[0m\n\u001b[0m                                                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "for bird in BIRDS:\n",
    "    print(f'predicting segments and labels for bird: {bird}')\n",
    "    config_ini = configs_by_bird[bird]\n",
    "    config_obj = ConfigParser()\n",
    "    config_obj.read(config_ini)\n",
    "\n",
    "    data_config = vak.config.data.parse_data_config(config_obj, config_ini)\n",
    "    train_config = vak.config.train.parse_train_config(config_obj, config_ini)\n",
    "    net_config = vak.config.parse._get_nets_config(config_obj, train_config.networks)\n",
    "\n",
    "    results_dir = config_obj['OUTPUT']['results_dir_made_by_main_script']\n",
    "    checkpoint_path = str(Path(results_dir).joinpath('TweetyNet'))\n",
    "    spect_scaler_path = str(Path(results_dir).joinpath('spect_scaler'))\n",
    "\n",
    "    # TODO: fix path\n",
    "    print(f'\\tgetting labelmap from {train_config.train_vds_path}')\n",
    "    train_vds = vak.dataset.VocalizationDataset.load(train_config.train_vds_path)\n",
    "    train_vds = train_vds.load_spects()\n",
    "    labelmap = train_vds.labelmap\n",
    "\n",
    "    bird_dirs_predict = dirs_to_predict[bird]    \n",
    "    for dir_to_predict in bird_dirs_predict:\n",
    "        stem = f'{dir_to_predict.parents[0].name}.{dir_to_predict.name}'\n",
    "\n",
    "        X_train = train_vds.spects_list()\n",
    "        X_train = np.concatenate(X_train, axis=1)\n",
    "        Y_train = train_vds.lbl_tb_list()\n",
    "        Y_train = np.concatenate(Y_train)\n",
    "        # transpose so rows are time bins\n",
    "        X_train = X_train.T\n",
    "        freq_bins = X_train.shape[-1]  # number of columns\n",
    "        \n",
    "        test_vds_fname = str(dir_to_predict.joinpath(\n",
    "            f'{stem}.test.vds.json'\n",
    "        ))\n",
    "\n",
    "        test_vds = vak.dataset.prep(str(dir_to_predict),\n",
    "                                    annot_format='notmat',\n",
    "                                    labelset=data_config.labelset,\n",
    "                                    output_dir=dir_to_predict,\n",
    "                                    save_vds=False,\n",
    "                                    vds_fname=test_vds_fname,\n",
    "                                    return_vds=True,\n",
    "                                    return_path=False,\n",
    "                                    audio_format='cbin',\n",
    "                                    spect_params=sp_nt)\n",
    "\n",
    "        net_name, net_config = list(net_config.items())[0]\n",
    "        n_classes = len(labelmap)\n",
    "        net_config_dict = net_config._asdict()\n",
    "        net_config_dict['n_syllables'] = n_classes\n",
    "        if 'freq_bins' in net_config_dict:\n",
    "            net_config_dict['freq_bins'] = freq_bins\n",
    "\n",
    "        X_test = test_vds.spects_list()\n",
    "        X_test = np.concatenate(X_test, axis=1)\n",
    "        # transpose so rows are time bins\n",
    "        X_test = X_test.T\n",
    "        Y_test = test_vds.lbl_tb_list()\n",
    "        Y_test = np.concatenate(Y_test)\n",
    "\n",
    "        (X_train,\n",
    "         _,\n",
    "         num_batches_train) = vak.utils.data.reshape_data_for_batching(X_train,\n",
    "                                                                       net_config.batch_size,\n",
    "                                                                       net_config.time_bins,\n",
    "                                                                       Y_train)\n",
    "\n",
    "        # Notice we don't reshape Y_test\n",
    "        (X_test,\n",
    "         _,\n",
    "         num_batches_test) = vak.utils.data.reshape_data_for_batching(X_test,\n",
    "                                                                      net_config.batch_size,\n",
    "                                                                      net_config.time_bins,\n",
    "                                                                      Y_test)\n",
    "        \n",
    "        \n",
    "        print(\"running test on data from {dir_to_predict}\")\n",
    "        (Y_pred_train,\n",
    "         Y_pred_test,\n",
    "         Y_pred_train_labels,\n",
    "         Y_pred_test_labels,\n",
    "         train_err,\n",
    "         train_lev,\n",
    "         train_syl_err_rate,\n",
    "         test_err,\n",
    "         test_lev,\n",
    "         test_syl_err_rate) = vak.core.learncurve.test_one_model(net_name,\n",
    "                                                                      net_config_dict,\n",
    "                                                                      NETWORKS,\n",
    "                                                                      n_classes,\n",
    "                                                                      labelmap,\n",
    "                                                                      checkpoint_path,\n",
    "                                                                      X_train,\n",
    "                                                                      Y_train,\n",
    "                                                                      num_batches_train,\n",
    "                                                                      X_test,\n",
    "                                                                      Y_test,\n",
    "                                                                      num_batches_test)\n",
    "\n",
    "        print(f'error on training set: {train_err}')\n",
    "        print(f'Levenstein distance on training set: {train_lev}')\n",
    "        print(f'syllable error rate on training set: {train_syl_err_rate}')\n",
    "        print(f'error on test set: {test_err}')\n",
    "        print(f'Levenstein distance on test set: {test_lev}')\n",
    "        print(f'syllable error rate on test set: {test_syl_err_rate}')\n",
    "        \n",
    "        err_dict = {\n",
    "            'train_err': train_err,\n",
    "            'train_lev': train_lev,\n",
    "            'train_syl_err_rate': train_syl_err_rate,\n",
    "            'test_err': test_err,\n",
    "            'test_lev': test_lev,\n",
    "            'test_syl_err_rate': test_syl_err_rate,\n",
    "        }\n",
    "        with open(os.path.joinpath(dir_to_predict,'test.json')) as fp:\n",
    "            json.dump(err_dict, fp)\n",
    "        \n",
    "        predict_vds_fname = str(dir_to_predict.joinpath(\n",
    "            f'{stem}.predict.vds.json'\n",
    "        ))\n",
    "        print(f'\\tmaking dataset for predictions from {dir_to_predict}')\n",
    "        predict_vds = vak.dataset.prep(str(dir_to_predict),\n",
    "                                       audio_format='cbin',\n",
    "                                       spect_params=sp_nt,\n",
    "                                       return_vds=True,\n",
    "                                       return_path=False)\n",
    "        predict_vds = predict_vds.clear_spects()\n",
    "        predict_vds.save(json_fname=predict_vds_fname)\n",
    "\n",
    "        print(f'\\trunning vak.core.predict on {dir_to_predict}')\n",
    "        vak.core.predict(\n",
    "            predict_vds_path=vds_fname,\n",
    "            checkpoint_path=checkpoint_path,\n",
    "            networks=net_config,\n",
    "            labelmap=labelmap,\n",
    "            spect_scaler_path=spect_scaler_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
