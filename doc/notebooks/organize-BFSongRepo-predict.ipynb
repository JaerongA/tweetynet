{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from configparser import ConfigParser\n",
    "import os\n",
    "from pathlib import Path\n",
    "import json\n",
    "import shutil\n",
    "\n",
    "import numpy as np\n",
    "import tqdm\n",
    "\n",
    "import vak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BIRDS = [\n",
    "#    'bl26lb16',\n",
    "    'gy6or6',\n",
    "#    'or60yw70',\n",
    "#    'gr41rd51',\n",
    "]\n",
    "\n",
    "CONFIGS_DIR = Path('../../src/configs/')\n",
    "BF_CONFIGS = sorted(list(CONFIGS_DIR.glob('*BFSongRepository*ini')))\n",
    "\n",
    "\n",
    "configs_by_bird = {\n",
    "    bird: [bf_config for bf_config in BF_CONFIGS if bird in str(bf_config)][0]\n",
    "    for bird in BIRDS\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BFSongRepo = Path('~/Documents/data/BFSongRepository/').expanduser()\n",
    "\n",
    "all_notmats = list(BFSongRepo.glob('*/*/*.not.mat'))\n",
    "bird_date_dirs = set([notmat.parents[0] for notmat in all_notmats])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "copy all .cbins with .not.mats into a sub-directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 11/196 [00:00<00:01, 99.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "copying annotated songs in /home/nickledave/Documents/data/BFSongRepository/gr41rd51/062112 into sub-directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 196/196 [00:01<00:00, 104.82it/s]\n",
      " 22%|██▏       | 11/51 [00:00<00:00, 104.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "copying annotated songs in /home/nickledave/Documents/data/BFSongRepository/or60yw70/100112 into sub-directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51/51 [00:00<00:00, 114.32it/s]\n",
      " 11%|█         | 8/75 [00:00<00:00, 76.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "copying annotated songs in /home/nickledave/Documents/data/BFSongRepository/bl26lb16/042112 into sub-directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 75/75 [00:01<00:00, 64.44it/s]\n",
      " 15%|█▌        | 11/73 [00:00<00:00, 107.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "copying annotated songs in /home/nickledave/Documents/data/BFSongRepository/or60yw70/092812 into sub-directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 73/73 [00:00<00:00, 110.07it/s]\n",
      " 29%|██▉       | 61/212 [00:00<00:00, 602.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "copying annotated songs in /home/nickledave/Documents/data/BFSongRepository/gy6or6/032412 into sub-directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 212/212 [00:00<00:00, 646.38it/s]\n",
      "  9%|▊         | 10/117 [00:00<00:01, 98.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "copying annotated songs in /home/nickledave/Documents/data/BFSongRepository/or60yw70/092912 into sub-directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 117/117 [00:01<00:00, 99.67it/s]\n",
      "  3%|▎         | 11/378 [00:00<00:03, 109.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "copying annotated songs in /home/nickledave/Documents/data/BFSongRepository/gr41rd51/062212 into sub-directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 378/378 [00:03<00:00, 100.65it/s]\n",
      "  2%|▏         | 3/162 [00:00<00:06, 23.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "copying annotated songs in /home/nickledave/Documents/data/BFSongRepository/bl26lb16/041912 into sub-directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 162/162 [00:02<00:00, 59.42it/s]\n",
      "  9%|▉         | 10/111 [00:00<00:01, 96.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "copying annotated songs in /home/nickledave/Documents/data/BFSongRepository/or60yw70/093012 into sub-directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 111/111 [00:01<00:00, 110.34it/s]\n",
      " 23%|██▎       | 50/215 [00:00<00:00, 496.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "copying annotated songs in /home/nickledave/Documents/data/BFSongRepository/gy6or6/032212 into sub-directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 215/215 [00:00<00:00, 574.96it/s]\n",
      " 43%|████▎     | 74/172 [00:00<00:00, 736.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "copying annotated songs in /home/nickledave/Documents/data/BFSongRepository/gy6or6/032512 into sub-directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 172/172 [00:00<00:00, 686.11it/s]\n",
      " 12%|█▏        | 11/92 [00:00<00:00, 105.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "copying annotated songs in /home/nickledave/Documents/data/BFSongRepository/gr41rd51/061912 into sub-directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 92/92 [00:00<00:00, 110.25it/s]\n",
      "  4%|▍         | 8/202 [00:00<00:02, 76.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "copying annotated songs in /home/nickledave/Documents/data/BFSongRepository/bl26lb16/042012 into sub-directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 202/202 [00:03<00:00, 58.52it/s]\n",
      " 17%|█▋        | 12/70 [00:00<00:00, 114.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "copying annotated songs in /home/nickledave/Documents/data/BFSongRepository/gr41rd51/062012 into sub-directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 70/70 [00:00<00:00, 111.72it/s]\n",
      " 39%|███▉      | 63/162 [00:00<00:00, 619.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "copying annotated songs in /home/nickledave/Documents/data/BFSongRepository/gy6or6/032312 into sub-directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 162/162 [00:00<00:00, 631.60it/s]\n",
      "  5%|▌         | 11/203 [00:00<00:01, 101.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "copying annotated songs in /home/nickledave/Documents/data/BFSongRepository/gr41rd51/062312 into sub-directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 203/203 [00:01<00:00, 108.29it/s]\n",
      "  9%|▉         | 8/87 [00:00<00:01, 76.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "copying annotated songs in /home/nickledave/Documents/data/BFSongRepository/or60yw70/092712 into sub-directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 87/87 [00:00<00:00, 96.31it/s]\n",
      "100%|██████████| 39/39 [00:00<00:00, 552.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "copying annotated songs in /home/nickledave/Documents/data/BFSongRepository/gy6or6/032612 into sub-directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# for bird_date_dir in bird_date_dirs:\n",
    "#     has_notmat = bird_date_dir.joinpath('has_notmat')\n",
    "#     has_notmat.mkdir(exist_ok=True)\n",
    "#     notmats_this_date_dir = sorted(list(bird_date_dir.glob('*.not.mat')))\n",
    "#     print(f'\\ncopying annotated songs in {bird_date_dir} into sub-directory')\n",
    "#     for notmat in tqdm.tqdm(notmats_this_date_dir):\n",
    "#         shutil.copy(notmat, dst=has_notmat)\n",
    "#         cbin = notmat.parent.joinpath(\n",
    "#             Path(notmat.stem).stem\n",
    "#         )\n",
    "#         shutil.copy(cbin, dst=has_notmat)  # cbin_file, stem.stem removes .not.mat\n",
    "#         rec = notmat.parent.joinpath(\n",
    "#             Path(Path(notmat.stem).stem).stem + '.rec'\n",
    "#         )\n",
    "#         shutil.copy(rec, dst=has_notmat)\n",
    "#         tmp = notmat.parent.joinpath(\n",
    "#             Path(Path(notmat.stem).stem).stem + '.tmp'\n",
    "#         )\n",
    "#        shutil.copy(tmp, dst=has_notmat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get dirs to predict for each bird"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs_to_predict = {}\n",
    "for bird in BIRDS:\n",
    "    these = [\n",
    "        bird_date_dir for bird_date_dir in bird_date_dirs\n",
    "        if bird in str(bird_date_dir)\n",
    "    ]\n",
    "    these = [path.joinpath('has_notmat')\n",
    "             for path in these]\n",
    "    dirs_to_predict[bird] = these"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "spect_params = {'fft_size': 512,\n",
    "                'step_size': 62,\n",
    "                'freq_cutoffs': [500, 10000],\n",
    "                'thresh': 6.25,\n",
    "                'transform_type': 'log_spect'}\n",
    "sp_nt = vak.config.spectrogram.SpectConfig(**spect_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "NETWORKS = vak.network._load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-7-e37b62efa538>, line 116)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-7-e37b62efa538>\"\u001b[0;36m, line \u001b[0;32m116\u001b[0m\n\u001b[0;31m    with open(os.path.joinpath(dir_to_predict,'test.json') as fp:\u001b[0m\n\u001b[0m                                                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "for bird in BIRDS:\n",
    "    print(f'predicting segments and labels for bird: {bird}')\n",
    "    config_ini = configs_by_bird[bird]\n",
    "    config_obj = ConfigParser()\n",
    "    config_obj.read(config_ini)\n",
    "\n",
    "    data_config = vak.config.data.parse_data_config(config_obj, config_ini)\n",
    "    train_config = vak.config.train.parse_train_config(config_obj, config_ini)\n",
    "    net_config = vak.config.parse._get_nets_config(config_obj, train_config.networks)\n",
    "\n",
    "    results_dir = config_obj['OUTPUT']['results_dir_made_by_main_script']\n",
    "    checkpoint_path = str(Path(results_dir).joinpath('TweetyNet'))\n",
    "    spect_scaler_path = str(Path(results_dir).joinpath('spect_scaler'))\n",
    "\n",
    "    # TODO: fix path\n",
    "    print(f'\\tgetting labelmap from {train_config.train_vds_path}')\n",
    "    train_vds = vak.dataset.VocalizationDataset.load(train_config.train_vds_path)\n",
    "    train_vds = train_vds.load_spects()\n",
    "    labelmap = train_vds.labelmap\n",
    "\n",
    "    bird_dirs_predict = dirs_to_predict[bird]    \n",
    "    for dir_to_predict in bird_dirs_predict:\n",
    "        stem = f'{dir_to_predict.parents[0].name}.{dir_to_predict.name}'\n",
    "\n",
    "        X_train = train_vds.spects_list()\n",
    "        X_train = np.concatenate(X_train, axis=1)\n",
    "        Y_train = train_vds.lbl_tb_list()\n",
    "        Y_train = np.concatenate(Y_train)\n",
    "        # transpose so rows are time bins\n",
    "        X_train = X_train.T\n",
    "        freq_bins = X_train.shape[-1]  # number of columns\n",
    "        \n",
    "        test_vds_fname = str(dir_to_predict.joinpath(\n",
    "            f'{stem}.test.vds.json'\n",
    "        ))\n",
    "\n",
    "        test_vds = vak.dataset.prep(str(dir_to_predict),\n",
    "                                    annot_format='notmat',\n",
    "                                    labelset=data_config.labelset,\n",
    "                                    output_dir=dir_to_predict,\n",
    "                                    save_vds=False,\n",
    "                                    vds_fname=test_vds_fname,\n",
    "                                    return_vds=True,\n",
    "                                    return_path=False,\n",
    "                                    audio_format='cbin',\n",
    "                                    spect_params=sp_nt)\n",
    "\n",
    "        net_name, net_config = list(net_config.items())[0]\n",
    "        n_classes = len(labelmap)\n",
    "        net_config_dict = net_config._asdict()\n",
    "        net_config_dict['n_syllables'] = n_classes\n",
    "        if 'freq_bins' in net_config_dict:\n",
    "            net_config_dict['freq_bins'] = freq_bins\n",
    "\n",
    "        X_test = test_vds.spects_list()\n",
    "        X_test = np.concatenate(X_test, axis=1)\n",
    "        # transpose so rows are time bins\n",
    "        X_test = X_test.T\n",
    "        Y_test = test_vds.lbl_tb_list()\n",
    "        Y_test = np.concatenate(Y_test)\n",
    "\n",
    "        (X_train,\n",
    "         _,\n",
    "         num_batches_train) = vak.utils.data.reshape_data_for_batching(X_train,\n",
    "                                                                       net_config.batch_size,\n",
    "                                                                       net_config.time_bins,\n",
    "                                                                       Y_train)\n",
    "\n",
    "        # Notice we don't reshape Y_test\n",
    "        (X_test,\n",
    "         _,\n",
    "         num_batches_test) = vak.utils.data.reshape_data_for_batching(X_test,\n",
    "                                                                      net_config.batch_size,\n",
    "                                                                      net_config.time_bins,\n",
    "                                                                      Y_test)\n",
    "        \n",
    "        \n",
    "        print(\"running test on data from {dir_to_predict}\")\n",
    "        (Y_pred_train,\n",
    "         Y_pred_test,\n",
    "         Y_pred_train_labels,\n",
    "         Y_pred_test_labels,\n",
    "         train_err,\n",
    "         train_lev,\n",
    "         train_syl_err_rate,\n",
    "         test_err,\n",
    "         test_lev,\n",
    "         test_syl_err_rate) = vak.core.learncurve.test_one_model(net_name,\n",
    "                                                                      net_config_dict,\n",
    "                                                                      NETWORKS,\n",
    "                                                                      n_classes,\n",
    "                                                                      labelmap,\n",
    "                                                                      checkpoint_path,\n",
    "                                                                      X_train,\n",
    "                                                                      Y_train,\n",
    "                                                                      num_batches_train,\n",
    "                                                                      X_test,\n",
    "                                                                      Y_test,\n",
    "                                                                      num_batches_test)\n",
    "\n",
    "        print(f'error on training set: {train_err}')\n",
    "        print(f'Levenstein distance on training set: {train_lev}')\n",
    "        print(f'syllable error rate on training set: {train_syl_err_rate}')\n",
    "        print(f'error on test set: {test_err}')\n",
    "        print(f'Levenstein distance on test set: {test_lev}')\n",
    "        print(f'syllable error rate on test set: {test_syl_err_rate}')\n",
    "        \n",
    "        err_dict = {\n",
    "            'train_err': train_err,\n",
    "            'train_lev': train_lev,\n",
    "            'train_syl_err_rate': train_syl_err_rate,\n",
    "            'test_err': test_err,\n",
    "            'test_lev': test_lev,\n",
    "            'test_syl_err_rate': test_syl_err_rate,\n",
    "        }\n",
    "        with open(os.path.joinpath(dir_to_predict,'test.json')) as fp:\n",
    "            json.dump(err_dict, fp)\n",
    "        \n",
    "        predict_vds_fname = str(dir_to_predict.joinpath(\n",
    "            f'{stem}.predict.vds.json'\n",
    "        ))\n",
    "        print(f'\\tmaking dataset for predictions from {dir_to_predict}')\n",
    "        predict_vds = vak.dataset.prep(str(dir_to_predict),\n",
    "                                       audio_format='cbin',\n",
    "                                       spect_params=sp_nt,\n",
    "                                       return_vds=True,\n",
    "                                       return_path=False)\n",
    "        predict_vds = predict_vds.clear_spects()\n",
    "        predict_vds.save(json_fname=predict_vds_fname)\n",
    "\n",
    "        print(f'\\trunning vak.core.predict on {dir_to_predict}')\n",
    "        vak.core.predict(\n",
    "            predict_vds_path=vds_fname,\n",
    "            checkpoint_path=checkpoint_path,\n",
    "            networks=net_config,\n",
    "            labelmap=labelmap,\n",
    "            spect_scaler_path=spect_scaler_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
