{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "import vak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BFSongRepo = Path('/home/bart/Documents/data/birdsong/BFSongRepository/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_notmats = list(BFSongRepo.glob('*/*/*.not.mat'))\n",
    "bird_date_dirs = set([notmat.parents[0] for notmat in all_notmats])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "for bird_date_dir in bird_date_dirs:\n",
    "    has_notmat = bird_date_dir.joinpath('has_notmat')\n",
    "    has_notmat.mkdir(exist_ok=True)\n",
    "    notmats_this_date_dir = sorted(list(bird_date_dir.glob('*.not.mat')))\n",
    "    for notmat in notmats_this_date_dir:\n",
    "        shutil.copy(notmat, dst=has_notmat)\n",
    "        cbin = notmat.parent.joinpath(\n",
    "            Path(notmat.stem).stem\n",
    "        )\n",
    "        shutil.copy(cbin, dst=has_notmat)  # cbin_file, stem.stem removes .not.mat\n",
    "        rec = notmat.parent.joinpath(\n",
    "            Path(Path(notmat.stem).stem).stem + '.rec'\n",
    "        )\n",
    "        shutil.copy(rec, dst=has_notmat)\n",
    "        tmp = notmat.parent.joinpath(\n",
    "            Path(Path(notmat.stem).stem).stem + '.tmp'\n",
    "        )\n",
    "        shutil.copy(tmp, dst=has_notmat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BIRDS = ['bl26lb16', 'gy6or6', 'or60yw70', 'gr41rd51']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs_to_predict = {}\n",
    "for bird in BIRDS:\n",
    "    dirs_to_predict[bird] = [\n",
    "        bird_date_dir for bird_date_dir in bird_date_dirs\n",
    "        if bird in str(bird_date_dir)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       "\u001b[0mvak\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mannot_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mlabelset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0moutput_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0msave_vds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mvds_fname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mreturn_vds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mreturn_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mload_spects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mannot_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0maudio_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mspect_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mspect_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mspect_output_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "prepare a VocalizationDataset from a directory of audio or spectrogram files\n",
       "containing vocalizations, and (optionally) annotation for those files\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "data_dir : str\n",
       "    path to directory with audio or spectrogram files from which to make dataset\n",
       "annot_format : str\n",
       "    format of annotations. Any format that can be used with the\n",
       "    crowsetta library is valid. Default is None.\n",
       "labelset : set, list\n",
       "    of str or int, set of labels for vocalizations. Default is None.\n",
       "    If not None, then files will be skipped where the 'labels' array in the\n",
       "    corresponding annotation contains labels that are not found in labelset\n",
       "output_dir : str\n",
       "    path to location where data sets should be saved. Default is None,\n",
       "    in which case data sets is saved in data_dir.\n",
       "save_vds : bool\n",
       "    if True, save the VocalizationDataset created as a .json file. Default is False.\n",
       "vds_fname : str\n",
       "    filename for VocalDataset, which will be saved as a .json file.\n",
       "    If filename does not end in .json, then that extension will be appended.\n",
       "    Default is None. If None, then the filename will be\n",
       "    'prep_{timestamp}.vds.json'.\n",
       "return_vds : bool\n",
       "    if True, return prepared VocalizationDataset. Default is True.\n",
       "return_path : bool\n",
       "    if True, return path to saved VocalizationDataset. Default is True.\n",
       "load_spects : bool\n",
       "    if True, load spectrograms. If False, return a VocalDataset without spectograms loaded.\n",
       "    Default is True. Set to False when you want to create a VocalDataset for use\n",
       "    later, but don't want to load all the spectrograms into memory yet.\n",
       "audio_format : str\n",
       "    format of audio files. One of {'wav', 'cbin'}.\n",
       "spect_format : str\n",
       "    format of array files containing spectrograms as 2-d matrices.\n",
       "    One of {'mat', 'npz'}.\n",
       "annot_file : str\n",
       "    Path to a single annotation file. Default is None.\n",
       "    Used when a single file contains annotations for multiple audio files.\n",
       "spect_params : dict\n",
       "    Dictionary of parameters for creating spectrograms.\n",
       "    Default is None (implying that spectrograms are already made).\n",
       "spect_output_dir : str\n",
       "    path to location where spectrogram files should be saved. Default is None,\n",
       "    in which case it defaults to 'spectrograms_generated_{time stamp}'.\n",
       "\n",
       "Returns\n",
       "-------\n",
       "vds : vak.dataset.VocalizationDataset\n",
       "    the VocalizationDataset prepared from the directory specified\n",
       "vds_path : str\n",
       "    path to where VocalizationDataset was saved\n",
       "\n",
       "Notes\n",
       "-----\n",
       "If dataset is created from audio files, then .spect.npz files will be\n",
       "generated from the audio files and saved in output_dir.\n",
       "\u001b[0;31mFile:\u001b[0m      ~/Documents/repos/birdsong/vak/src/vak/dataset/prep.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vak.dataset.prep(\n",
    "    data_dir,\n",
    "    audio_format='cbin'\n",
    "    spect_params=spect_params\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       "\u001b[0mvak\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcli\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mnetworks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mlabels_mapping_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mspect_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdir_to_predict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmat_spect_files_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mspect_scaler_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "make predictions with one trained model\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "checkpoint_path : str\n",
       "    path to directory with saved model\n",
       "networks : dict\n",
       "    where each key is the name of a neural network and the corresponding\n",
       "    value is the configuration for that network (in a namedtuple or a dict)\n",
       "labels_mapping_path : str\n",
       "    path to file that contains labels mapping, to convert output from consecutive\n",
       "    digits back to labels used for audio segments (e.g. birdsong syllables)\n",
       "spect_params : dict\n",
       "    Dictionary of parameters for creating spectrograms.\n",
       "dir_to_predict : str\n",
       "    path to directory where input files are located\n",
       "mat_spect_files_path\n",
       "    path to directory with .mat files containing spectrograms that should be used\n",
       "    as data for which predictions are made\n",
       "spect_scaler_path : str\n",
       "    path to a saved SpectScaler object used to normalize spectrograms.\n",
       "    If spectrograms were normalized and this is not provided, will give\n",
       "    incorrect results.\n",
       "    Default is None.\n",
       "\n",
       "Returns\n",
       "-------\n",
       "None\n",
       "\u001b[0;31mFile:\u001b[0m      ~/Documents/repos/birdsong/vak/src/vak/cli/predict.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vak.cli.predict(\n",
    "    checkpoint_path,\n",
    "    networks,\n",
    "    labels_mapping_path,\n",
    "    spect_params,\n",
    "    dir_to_predict=None,\n",
    "    mat_spect_files_path=None,\n",
    "    spect_scaler_path=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
