{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## the problem\n",
    "Even though error rates are low, creating transition matrices from predicted labels gives very different results from the same matrices created from ground truth labels.\n",
    "\n",
    "Why?\n",
    "\n",
    "`vak.core.predict` currently does not use the same function that `vak.core.learncurve.test` uses to find segments from predicted timebin labels. The `vak.core.predict` function is more computationally expensive because it finds times of onsets and offsets, while the `vak.core.learncurve.test` function just finds wherever labels change and returning the first label after each change point (which will be the same for the rest of the segment).\n",
    "\n",
    "So worst case scenario would be if those functions give different results.\n",
    "There are tests for this already but maybe they are missing something that only emerges from bigger datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load a network and get predictions\n",
    "you can ignore most of this code and scroll to comments below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from configparser import ConfigParser\n",
    "from glob import glob\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "import joblib\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tqdm\n",
    "\n",
    "import vak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "VDS_PATH = Path(\n",
    "    '/home/nickledave/Documents/data/BFSongRepository/vak/gy6or6/'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vds_path = str(VDS_PATH.joinpath('_prep_190726_153000.train.vds.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed |  0.4s\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "train_vds = vak.Dataset.load(json_fname=train_vds_path)\n",
    "\n",
    "if train_vds.are_spects_loaded() is False:\n",
    "    train_vds = train_vds.load_spects()\n",
    "\n",
    "X_train = train_vds.spects_list()\n",
    "X_train = np.concatenate(X_train, axis=1)\n",
    "Y_train = train_vds.lbl_tb_list()\n",
    "Y_train = np.concatenate(Y_train)\n",
    "# transpose so rows are time bins\n",
    "X_train = X_train.T\n",
    "\n",
    "n_classes = len(train_vds.labelmap)\n",
    "print(n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "TWEETYNET_VDS_PATH = Path('/home/nickledave/Documents/repos/tweetynet/data/BFSongRepository/gy6or6/vds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_vds_path = list(TWEETYNET_VDS_PATH.glob('*test.vds.json'))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_replicates = 4\n",
    "train_set_durs = [60, 120, 480]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed |  6.3s\n"
     ]
    }
   ],
   "source": [
    "test_vds = vak.Dataset.load(json_fname=test_vds_path)\n",
    "\n",
    "if test_vds.are_spects_loaded() is False:\n",
    "    test_vds = test_vds.load_spects()\n",
    "\n",
    "if test_vds.labelmap != train_vds.labelmap:\n",
    "    raise ValueError(\n",
    "        f'labelmap of test set, {test_vds.labelmap}, does not match labelmap of training set, '\n",
    "        f'{train_vds.labelmap}'\n",
    "    )\n",
    "\n",
    "def unpack_test():\n",
    "    \"\"\"helper function because we want to get back test set unmodified every time we go through\n",
    "    main loop below, without copying giant arrays\"\"\"\n",
    "    X_test = test_vds.spects_list()\n",
    "    X_test = np.concatenate(X_test, axis=1)\n",
    "    # transpose so rows are time bins\n",
    "    X_test = X_test.T\n",
    "    Y_test = test_vds.lbl_tb_list()\n",
    "    Y_test = np.concatenate(Y_test)\n",
    "    return X_test, Y_test\n",
    "\n",
    "# just get X_test to make sure it has the right shape\n",
    "X_test, _ = unpack_test()\n",
    "if X_train.shape[-1] != X_test.shape[-1]:\n",
    "    raise ValueError(f'Number of frequency bins in training set spectrograms, {X_train.shape[-1]}, '\n",
    "                     f'does not equal number in test set spectrograms, {X_test.shape[-1]}.')\n",
    "freq_bins = X_test.shape[-1]  # number of columns\n",
    "\n",
    "# concatenate labels into one big string\n",
    "# used for Levenshtein distance + syllable error rate\n",
    "Y_train_labels = [voc.annot.labels.tolist() for voc in train_vds.voc_list]\n",
    "Y_train_labels_for_lev = ''.join([chr(lbl) if type(lbl) is int else lbl\n",
    "                                  for labels in Y_train_labels for lbl in labels])\n",
    "Y_test_labels = [voc.annot.labels.tolist() for voc in test_vds.voc_list]\n",
    "Y_test_labels_for_lev = ''.join([chr(lbl) if type(lbl) is int else lbl\n",
    "                                 for labels in Y_test_labels for lbl in labels])\n",
    "\n",
    "replicates = range(1, num_replicates + 1)\n",
    "\n",
    "NETWORKS = vak.network._load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate labels into one big string\n",
    "# used for Levenshtein distance + syllable error rate\n",
    "Y_train_labels = [voc.annot.labels.tolist() for voc in train_vds.voc_list]\n",
    "Y_train_labels_for_lev = ''.join([chr(lbl) if type(lbl) is int else lbl\n",
    "                                  for labels in Y_train_labels for lbl in labels])\n",
    "Y_test_labels = [voc.annot.labels.tolist() for voc in test_vds.voc_list]\n",
    "Y_test_labels_for_lev = ''.join([chr(lbl) if type(lbl) is int else lbl\n",
    "                                 for labels in Y_test_labels for lbl in labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = str(\n",
    "    '/home/nickledave/Documents/repos/tweetynet/src/configs/config_BFSongRepository_gy6or6_.ini'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_config = vak.config.parse_config(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_dur = 60\n",
    "replicate = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "training_records_path = '/home/nickledave/Documents/data/BFSongRepository/vak/gy6or6/results_190726_153021'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "spect_scaler = joblib.load(\n",
    "    os.path.join(training_records_path, 'spect_scaler'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "(net_name, net_config) = tuple(a_config.networks.items())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, Y_test = unpack_test()\n",
    "# Normalize before reshaping to avoid even more convoluted array reshaping.\n",
    "X_test = spect_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice we don't reshape Y_test\n",
    "(X_test,\n",
    " _,\n",
    " num_batches_test) = vak.utils.data.reshape_data_for_batching(\n",
    "    X_test,\n",
    "    net_config.batch_size,\n",
    "    net_config.time_bins,\n",
    "    Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_config_dict = net_config._asdict()\n",
    "net_config_dict['n_syllables'] = n_classes\n",
    "if 'freq_bins' in net_config_dict:\n",
    "    net_config_dict['freq_bins'] = freq_bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dirname_this_net = os.path.join(training_records_path, net_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/nickledave/anaconda3/envs/vak-env/lib/python3.6/site-packages/tweetynet/model.py:227: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.conv2d instead.\n",
      "WARNING:tensorflow:From /home/nickledave/anaconda3/envs/vak-env/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/nickledave/anaconda3/envs/vak-env/lib/python3.6/site-packages/tweetynet/model.py:232: max_pooling2d (from tensorflow.python.layers.pooling) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.max_pooling2d instead.\n",
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From /home/nickledave/anaconda3/envs/vak-env/lib/python3.6/site-packages/tweetynet/model.py:260: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From /home/nickledave/anaconda3/envs/vak-env/lib/python3.6/site-packages/tweetynet/model.py:270: bidirectional_dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.Bidirectional(keras.layers.RNN(cell))`, which is equivalent to this API\n",
      "WARNING:tensorflow:From /home/nickledave/anaconda3/envs/vak-env/lib/python3.6/site-packages/tensorflow/python/ops/rnn.py:443: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From /home/nickledave/anaconda3/envs/vak-env/lib/python3.6/site-packages/tensorflow/python/ops/rnn.py:626: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "net = NETWORKS[net_name](**net_config_dict)\n",
    "\n",
    "# we use latest checkpoint when doing summary for learncurve, assume that's \"best trained\"\n",
    "checkpoint_file = tf.train.latest_checkpoint(checkpoint_dir=results_dirname_this_net)\n",
    "\n",
    "meta_file = glob(checkpoint_file + '*meta')\n",
    "if len(meta_file) != 1:\n",
    "    raise ValueError('Incorrect number of meta files for last saved checkpoint.\\n'\n",
    "                     'For checkpoint {}, found these files:\\n'\n",
    "                     '{}'\n",
    "                     .format(checkpoint_file, meta_file))\n",
    "else:\n",
    "    meta_file = meta_file[0]\n",
    "\n",
    "data_file = glob(checkpoint_file + '*data*')\n",
    "if len(data_file) != 1:\n",
    "    raise ValueError('Incorrect number of data files for last saved checkpoint.\\n'\n",
    "                     'For checkpoint {}, found these files:\\n'\n",
    "                     '{}'\n",
    "                     .format(checkpoint_file, data_file))\n",
    "else:\n",
    "    data_file = data_file[0]\n",
    "\n",
    "with tf.Session(graph=net.graph) as sess:\n",
    "    tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "    net.restore(sess=sess,\n",
    "                meta_file=meta_file,\n",
    "                data_file=data_file)\n",
    "\n",
    "    for b in range(num_batches_test):  # \"b\" is \"batch number\"\n",
    "        d = {\n",
    "            net.X: X_test[:, b * net_config_dict['time_bins']: (b + 1) * net_config_dict['time_bins'], :],\n",
    "            net.lng: [net_config_dict['time_bins']] * net_config_dict['batch_size']}\n",
    "\n",
    "        if 'Y_pred_test' in locals():\n",
    "            preds = sess.run(net.predict, feed_dict=d)\n",
    "            preds = preds.reshape(net_config_dict['batch_size'], -1)\n",
    "            Y_pred_test = np.concatenate((Y_pred_test, preds),\n",
    "                                         axis=1)\n",
    "        else:\n",
    "            Y_pred_test = sess.run(net.predict, feed_dict=d)\n",
    "            Y_pred_test = Y_pred_test.reshape(net_config_dict['batch_size'], -1)\n",
    "\n",
    "    # again get rid of zero padding predictions\n",
    "    Y_pred_test = Y_pred_test.ravel()[:Y_test.shape[0], np.newaxis]\n",
    "    test_err = np.sum(Y_pred_test != Y_test) / Y_test.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## okay, now look at predictions -- does `vak.test` output match `vak.predict`?\n",
    "We make sure `Y_pred_test` is an array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9],\n",
       "       [9],\n",
       "       [9],\n",
       "       ...,\n",
       "       [0],\n",
       "       [0],\n",
       "       [0]], dtype=int32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_lbl_tb_list = test_vds.lbl_tb_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the lengths of each of the individual labeled timebins vectors for each spectrogram, so we can split `Y_pred_test` up into vectors of the same sizes below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_lens = [arr.shape for arr in Y_test_lbl_tb_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But before we split them up, answer the question we asked above:  \n",
    "how different is output of `lbl_tb2segments` (used by `vak.core.predict`) compared to output of `lbl_tb2label` (used by `vak.core.learncurve.test`)?\n",
    "\n",
    "First of all:  \n",
    "do they return vectors of the same length?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_test_seg = vak.utils.labels.lbl_tb2labels(Y_pred_test, train_vds.labelmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12419"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Y_pred_test_seg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "timebin_dur = set([voc.metaspect.timebin_dur for voc in train_vds.voc_list])\n",
    "timebin_dur = timebin_dur.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_test_lbl, onsets, offsets = vak.utils.labels.lbl_tb2segments(Y_pred_test,\n",
    "                                                                    train_vds.labelmap,\n",
    "                                                                    timebin_dur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12419,)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred_test_lbl.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes, vectors returned by each function are the same length.\n",
    "\n",
    "Okay, what is the edit distance between them?  \n",
    "If 0, it's the same vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_test_lbl_str = ''.join(Y_pred_test_lbl.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vak.metrics.levenshtein(Y_pred_test_seg, Y_pred_test_lbl_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be extra sure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred_test_seg == Y_pred_test_lbl_str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, so that's not the problem -- we're getting the same result for all intents and purposes from `test` and `predict`.\n",
    "\n",
    "## if that's not the problem, what is?\n",
    "\n",
    "So even though error is low, maybe we're not recovering the same segments from `predict` that we have in the test set?\n",
    "\n",
    "To figure that out, we need to go ahead and split up `Y_pred` into labeled timebin vectors of the same size as those in the original test set, segment each vector, and then look at the segments we get out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "starts = [0]\n",
    "stops = []\n",
    "current_start = 0\n",
    "for a_len in Y_test_lens:\n",
    "    a_len = a_len[0]\n",
    "    stops.append(current_start + a_len)\n",
    "    current_start += a_len\n",
    "    if current_start < Y_test.shape[0]:\n",
    "        starts.append(current_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_lbl_tb_list = []\n",
    "for start, stop in zip(starts, stops):\n",
    "    Y_pred_lbl_tb_list.append(Y_pred_test[start:stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_lens = [arr.shape for arr in Y_pred_lbl_tb_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all([pred_len == test_len for pred_len, test_len in zip(Y_pred_lens, Y_test_lens)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_labels = []\n",
    "Y_pred_onsets = []\n",
    "Y_pred_offsets = []\n",
    "for a_pred_lbl_tb in Y_pred_lbl_tb_list:\n",
    "    lbl, on, off = vak.utils.labels.lbl_tb2segments(a_pred_lbl_tb, train_vds.labelmap, timebin_dur)\n",
    "    Y_pred_labels.append(lbl)\n",
    "    Y_pred_onsets.append(on)\n",
    "    Y_pred_offsets.append(off)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['i', 'i', 'i', 'i', 'i', 'i', 'i', 'b', 'i', 'i', 'i', 'a', 'b',\n",
       "       'c', 'd', 'e', 'e', 'e', 'f', 'g', 'h', 'j', 'k', 'i', 'a', 'b',\n",
       "       'c', 'd', 'e', 'e', 'f', 'g', 'h', 'j', 'k', 'i', 'a', 'b', 'b',\n",
       "       'c', 'd', 'e', 'e', 'f', 'g', 'h', 'j', 'k', 'i', 'a', 'b', 'c',\n",
       "       'd', 'e', 'e', 'f'], dtype='<U1')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56,)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred_labels[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_labels_from_seg = []\n",
    "Y_test_onsets = []\n",
    "Y_test_offsets = []\n",
    "for a_test_lbl_tb in Y_test_lbl_tb_list:\n",
    "    lbl, on, off = vak.utils.labels.lbl_tb2segments(a_test_lbl_tb, train_vds.labelmap, timebin_dur)\n",
    "    Y_test_labels_from_seg.append(lbl)\n",
    "    Y_test_onsets.append(on)\n",
    "    Y_test_offsets.append(off)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['i', 'i', 'i', 'i', 'i', 'i', 'a', 'b', 'c', 'd', 'e', 'e', 'f',\n",
       "       'g', 'h', 'j', 'k', 'i', 'a', 'b', 'c', 'd', 'e', 'e', 'f', 'g',\n",
       "       'h', 'j', 'k', 'i', 'a', 'b', 'c', 'd', 'e', 'e', 'f', 'g', 'h',\n",
       "       'j', 'k', 'i', 'a', 'b', 'c', 'd', 'e', 'e', 'f'], dtype='<U1')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test_labels_from_seg[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49,)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test_labels_from_seg[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Y_test_labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At least for the first vector, there are more segments in the predicted labels.\n",
    "\n",
    "These could be segments that are not in the ground-truth labels because the person annotating the song removed them.\n",
    "\n",
    "As a sanity check, do we recover the ground truth labels if we apply `vak.utils.lbl_tb2segments` to the ground truth label vector?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array_equal(Y_test_labels[0], Y_test_seg_list[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes, we do.\n",
    "\n",
    "So, yes, we're getting extra segments in our predictions somewhere.\n",
    "\n",
    "How frequent is this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "same_lengths = [Y_pred_seg.shape == Y_test_seg.shape for Y_pred_seg, Y_test_seg in zip(Y_pred_seg_list, Y_test_seg_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% with accurate length:  0.0357\n"
     ]
    }
   ],
   "source": [
    "len_acc = sum(same_lengths) / len(same_lengths)\n",
    "print(f'% with accurate length: {len_acc: 0.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only about 3% of them are the right lengths\n",
    "\n",
    "So what if we subtract the number of segments in the predicted labels from the number in the ground truth labels?  \n",
    "If the number is negative, there are more segments in the predicted labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "length_diffs = [Y_test_seg.shape[0] - Y_pred_seg.shape[0] for Y_pred_seg, Y_test_seg in zip(Y_pred_seg_list, Y_test_seg_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-7, -5, -5, -12, -4]\n"
     ]
    }
   ],
   "source": [
    "print(length_diffs[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-7.666666666666667"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(length_diffs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes, there are more segments in the predicted labels.\n",
    "\n",
    "Two approaches to cleaning up:  \n",
    "(1) remove segments lower than a certain duration  \n",
    "  + this might help if all the spurious segments are shorter than typical syllables  \n",
    "  + it won't help though if e.g. calls are being labeled as syllables, and those calls would have been segments in the ground truth data, but the annotator removed those segments since they weren't syllables  \n",
    "  + problem: what label to give the segment to throw away? If silence on both sides (probably almost all cases) could just set to silence?   \n",
    "\n",
    "(2) remove segments based on syntax  \n",
    "  + throw away segments where label is below some threshold of ever occurring  \n",
    "  + this prevents us from doing an analysis where we ask if recovered original syntax, though  \n",
    "  + because of course we cover the original syntax if we use the original syntax to throw away things that don't match it  \n",
    "  + but I think this is a good way to show the work that actually needs to be done to get this to be useful in the lab, and highlights issues with previous work  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/nickledave/Documents/data/BFSongRepository/gy6or6/032212\n"
     ]
    }
   ],
   "source": [
    "cd ~/Documents/data/BFSongRepository/gy6or6/032212/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "notmats = glob('*.not.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "notmat0 = loadmat(notmats[0], squeeze_me=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_dur = notmat0['min_dur']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.936, 1.1  , 1.292, 1.462, 1.636, 1.814, 1.972, 2.064, 2.166,\n",
       "       2.236, 2.31 , 2.382, 2.458, 2.584, 2.704, 2.762, 2.834, 3.054,\n",
       "       3.206, 3.3  , 3.408, 3.48 , 3.554, 3.628, 3.698, 3.83 , 3.968,\n",
       "       4.022, 4.098, 4.322, 4.492, 4.584, 4.696, 4.772, 4.844, 4.92 ,\n",
       "       4.994, 5.128, 5.27 , 5.324, 5.404, 5.624, 5.796, 5.892, 5.996,\n",
       "       6.074, 6.148, 6.222, 6.298])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test_onsets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.   , 0.348, 0.392, 0.924, 1.1  , 1.294, 1.462, 1.466, 1.468,\n",
       "       1.636, 1.814, 1.97 , 2.064, 2.166, 2.236, 2.308, 2.382, 2.458,\n",
       "       2.46 , 2.584, 2.704, 2.762, 2.836, 3.054, 3.208, 3.3  , 3.406,\n",
       "       3.48 , 3.554, 3.628, 3.698, 3.83 , 3.968, 4.024, 4.096, 4.324,\n",
       "       4.492, 4.584, 4.624, 4.696, 4.772, 4.844, 4.92 , 4.992, 5.128,\n",
       "       5.268, 5.324, 5.402, 5.624, 5.796, 5.89 , 5.998, 6.074, 6.148,\n",
       "       6.222, 6.298])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred_onsets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 56.  78.  88. 108.  92.  84.  40.  36.  52.  62.  62.  58.  80.  42.\n",
      "  42.  66.  88.  86.  40.  34.  54.  64.  62.  54.  80.  38.  36.  68.\n",
      "  92.  90.  38.  34.  58.  62.  62.  56.  74.  42.  40.  68.  86.  88.\n",
      "  38.  38.  60.  62.  64.  58.  78.]\n",
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True]\n"
     ]
    }
   ],
   "source": [
    "durs_test_0 = (Y_test_offsets[0] - Y_test_onsets[0]) * 1000\n",
    "print(durs_test_0)\n",
    "print(durs_test_0 > min_dur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 36.   2.  38.  76.  78.  84.   2.   0. 102.  90.  84.  40.  38.  52.\n",
      "  60.  62.  60.   0.  78.  42.  40.  68.  86.  90.  36.  32.  58.  62.\n",
      "  62.  52.  78.  40.  36.  66.  94.  90.  38.  34.   6.  58.  64.  60.\n",
      "  54.  78.  42.  40.  68.  88.  90.  38.  40.  58.  64.  62.  58.  80.]\n",
      "[ True False  True  True  True  True False False  True  True  True  True\n",
      "  True  True  True  True  True False  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True False  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True]\n"
     ]
    }
   ],
   "source": [
    "durs_pred_0 = (Y_pred_offsets[0] - Y_pred_onsets[0]) * 1000\n",
    "print(durs_pred_0)\n",
    "print(durs_pred_0 > min_dur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.trunc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mCall signature:\u001b[0m  \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mType:\u001b[0m            ufunc\n",
       "\u001b[0;31mString form:\u001b[0m     <ufunc 'trunc'>\n",
       "\u001b[0;31mFile:\u001b[0m            ~/anaconda3/envs/vak-env/lib/python3.6/site-packages/numpy/__init__.py\n",
       "\u001b[0;31mDocstring:\u001b[0m      \n",
       "trunc(x, /, out=None, *, where=True, casting='same_kind', order='K', dtype=None, subok=True[, signature, extobj])\n",
       "\n",
       "Return the truncated value of the input, element-wise.\n",
       "\n",
       "The truncated value of the scalar `x` is the nearest integer `i` which\n",
       "is closer to zero than `x` is. In short, the fractional part of the\n",
       "signed number `x` is discarded.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "x : array_like\n",
       "    Input data.\n",
       "out : ndarray, None, or tuple of ndarray and None, optional\n",
       "    A location into which the result is stored. If provided, it must have\n",
       "    a shape that the inputs broadcast to. If not provided or `None`,\n",
       "    a freshly-allocated array is returned. A tuple (possible only as a\n",
       "    keyword argument) must have length equal to the number of outputs.\n",
       "where : array_like, optional\n",
       "    Values of True indicate to calculate the ufunc at that position, values\n",
       "    of False indicate to leave the value in the output alone.\n",
       "**kwargs\n",
       "    For other keyword-only arguments, see the\n",
       "    :ref:`ufunc docs <ufuncs.kwargs>`.\n",
       "\n",
       "Returns\n",
       "-------\n",
       "y : ndarray or scalar\n",
       "    The truncated value of each element in `x`.\n",
       "    This is a scalar if `x` is a scalar.\n",
       "\n",
       "See Also\n",
       "--------\n",
       "ceil, floor, rint\n",
       "\n",
       "Notes\n",
       "-----\n",
       ".. versionadded:: 1.3.0\n",
       "\n",
       "Examples\n",
       "--------\n",
       ">>> a = np.array([-1.7, -1.5, -0.2, 0.2, 1.5, 1.7, 2.0])\n",
       ">>> np.trunc(a)\n",
       "array([-1., -1., -0.,  0.,  1.,  1.,  2.])\n",
       "\u001b[0;31mClass docstring:\u001b[0m\n",
       "Functions that operate element by element on whole arrays.\n",
       "\n",
       "To see the documentation for a specific ufunc, use `info`.  For\n",
       "example, ``np.info(np.sin)``.  Because ufuncs are written in C\n",
       "(for speed) and linked into Python with NumPy's ufunc facility,\n",
       "Python's help() function finds this page whenever help() is called\n",
       "on a ufunc.\n",
       "\n",
       "A detailed explanation of ufuncs can be found in the docs for :ref:`ufuncs`.\n",
       "\n",
       "Calling ufuncs:\n",
       "===============\n",
       "\n",
       "op(*x[, out], where=True, **kwargs)\n",
       "Apply `op` to the arguments `*x` elementwise, broadcasting the arguments.\n",
       "\n",
       "The broadcasting rules are:\n",
       "\n",
       "* Dimensions of length 1 may be prepended to either array.\n",
       "* Arrays may be repeated along dimensions of length 1.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "*x : array_like\n",
       "    Input arrays.\n",
       "out : ndarray, None, or tuple of ndarray and None, optional\n",
       "    Alternate array object(s) in which to put the result; if provided, it\n",
       "    must have a shape that the inputs broadcast to. A tuple of arrays\n",
       "    (possible only as a keyword argument) must have length equal to the\n",
       "    number of outputs; use `None` for uninitialized outputs to be\n",
       "    allocated by the ufunc.\n",
       "where : array_like, optional\n",
       "    Values of True indicate to calculate the ufunc at that position, values\n",
       "    of False indicate to leave the value in the output alone.  Note that if\n",
       "    an uninitialized return array is created via the default ``out=None``,\n",
       "    then the elements where the values are False will remain uninitialized.\n",
       "**kwargs\n",
       "    For other keyword-only arguments, see the :ref:`ufunc docs <ufuncs.kwargs>`.\n",
       "\n",
       "Returns\n",
       "-------\n",
       "r : ndarray or tuple of ndarray\n",
       "    `r` will have the shape that the arrays in `x` broadcast to; if `out` is\n",
       "    provided, it will be returned. If not, `r` will be allocated and\n",
       "    may contain uninitialized values. If the function has more than one\n",
       "    output, then the result will be a tuple of arrays.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.trunc?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
