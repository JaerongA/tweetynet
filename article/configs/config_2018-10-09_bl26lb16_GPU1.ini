[TweetyNet]
batch_size = 11
time_bins = 88
learning_rate = 0.001

[SPECTROGRAM]
fft_size = 512
step_size = 64
freq_cutoffs = 500, 10000
thresh = 6.25
log_transform = True

[DATA]
labelset = iabcdef
data_dir = ~/data/bf-repository/bl26lb16/041912
total_train_set_duration = 600
validation_set_duration = 250
test_set_duration = 500
output_dir = ~/data/bf-repository/bl26lb16/041912
skip_files_with_labels_not_in_labelset = Yes
freq_bins = 257

[TRAIN]
normalize_spectrograms = Yes
train_data_path = /home/art/data/bf-repository/bl26lb16/041912/spectrograms_190317_215326/train_data_dict
val_data_path = /home/art/data/bf-repository/bl26lb16/041912/spectrograms_190317_215326/val_data_dict
test_data_path = /home/art/data/bf-repository/bl26lb16/041912/spectrograms_190317_215326/test_data_dict
use_train_subsets_from_previous_run = No
previous_run_path = None
num_epochs = 2
val_error_step = 150
checkpoint_step = 600
save_only_single_checkpoint_file = True
patience = None
train_set_durs = 30, 45, 75, 120, 180, 240, 480
replicates = 5
networks = TweetyNet

[OUTPUT]
root_results_dir = ~/data/tweetynet_output/

